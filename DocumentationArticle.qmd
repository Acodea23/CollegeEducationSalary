---
title: "Documentation Article"
author: "Corbin Brinkerhoff, Matthew Wilson"
format: pdf
editor: visual
---

## Statistical Model

#### Mathematical Model

$\text{Salary}_i  = \beta_0  + \beta_1 \,\text{Sex}_i + \beta_j \,\text{Major}_{ij} + \beta_3 \,\text{GPA}_i + \varepsilon_i, \qquad  \varepsilon_i \sim \mathcal{N}(0,\sigma^2).$

Here the $Major_{ij}$ indicates that the ith quantity for major is the jth major. And $\beta_j$ is the beta coefficient for the jth major

#### Prediction Justification

```{r}
library(tidyverse)
```

```{r}
sal_df <- vroom::vroom("Salary.csv")

sal_df <- sal_df |>
  mutate(
    MajorCategory = factor(MajorCategory),
    Sex = factor(Sex)
  )

cross_validate <- function(k){
  val_set <- sal_df |> filter(folds == k)
  train_set <- sal_df |> filter(folds != k)
  
  preds <- predict.lm(lm(Salary ~ MajorCategory + Sex + GPA, data = train_set),
            newdata = val_set)
  sqrt(mean((preds - val_set[["Salary"]])^2))
}

K <- 5

folds <- rep(1:K, length = nrow(sal_df))|>
  sample()


rmse_results <- sapply(1:K, FUN = cross_validate)

print(sd(sal_df[["Salary"]]))
print(mean(rmse_results))
print(summary(rmse_results))
```

We performed k-fold CV and used the metric of RMSE. We can see that our model does decently well in predicting the variance in salary compared to the variance of the salaries in the data set. We can also see that the results are rather consistent across folds. Model Description

#### Sect 2

#### Sect 3

We created a linear model using major to predict salary. We then looked at the F-statistic for the model and saw that major was significant. We then looked at the beta coefficients of the different majors to determine which majors had the largest positive coefficients as that indicated which majors had the highest salaries on average.

#### Sect 4

#### Sect 5

We compared models with and without interactions. The F-test showed the model with interactions was significant. But their adjusted R-squared values are similar, and the K-fold CV results show that the predictive RMSE is similar. So we consider the simpler model to be a better choice. We also compared our predictive rmse to the sd of the dataset and saw that our rmse was significantly smaller than the sd, which means it better explained the variance in the data.

## Code Appendix

## 
