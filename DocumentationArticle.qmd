---
title: "Documentation Article"
author: "Corbin Brinkerhoff, Matthew Wilson"
format: pdf
editor: visual
---

## Statistical Model

#### Mathematical Model

$\text{Salary}_i  = \beta_0  + \beta_1 \,\text{Sex}_i + \beta_j \,\text{Major}_{ij} + \beta_3 \,\text{GPA}_i + \varepsilon_i, \qquad  \varepsilon_i \sim \mathcal{N}(0,\sigma^2).$

Here the $Major_{ij}$ indicates that the ith quantity for major is the jth major. And $\beta_j$ is the beta coefficient for the jth major

#### Prediction Justification

```{r}
library(tidyverse)
```

```{r}
sal_df <- vroom::vroom("Salary.csv")

sal_df <- sal_df |>
  mutate(
    MajorCategory = factor(MajorCategory),
    Sex = factor(Sex)
  )

cross_validate <- function(k){
  val_set <- sal_df |> filter(folds == k)
  train_set <- sal_df |> filter(folds != k)
  
  preds <- predict.lm(lm(Salary ~ MajorCategory + Sex + GPA, data = train_set),
            newdata = val_set)
  sqrt(mean((preds - val_set[["Salary"]])^2))
}

K <- 5

folds <- rep(1:K, length = nrow(sal_df))|>
  sample()


rmse_results <- sapply(1:K, FUN = cross_validate)

print(sd(sal_df[["Salary"]]))
print(mean(rmse_results))
print(summary(rmse_results))
```

We performed k-fold CV and used the metric of RMSE. We can see that our model does decently well in predicting the variance in salary compared to the variance of the salaries in the data set. We can also see that the results are rather consistent across folds. Model Description

#### Sect 2

We fit a linear regression of salary on GPA (`sal_lm`), then extracted the GPA slope (Beta Hat) and its two‑sided t‑test p‑value from `summary(sal_lm)$coefficients` to test H0: Beta(GPA) = 0. We quantified uncertainty by computing the 95% Wald confidence interval for Beta(GPA) with `confint(sal_lm, "GPA", level = 0.95)` and printed the estimate, p‑value, and CI using `cat(...)` with light rounding. To assess moderation by Major and obtain adjusted main‑effect tests in the presence of an interaction, we set sum‑to‑zero contrasts (`options(contrasts =     ("contr.sum","contr.poly"))`) and ran a Type III ANOVA on `sal_lm_int_GPA_MAJ` via `car::Anova(..., type = 3)`. Interpretation uses the simple model for the marginal GPA effect (estimate, p‑value, CI) and the Type III ANOVA to determine whether GPA’s slope varies by Major (interaction) and to evaluate adjusted main effects.

#### Sect 3

We created a linear model using major to predict salary. We then looked at the F-statistic for the model and saw that major was significant. We then looked at the beta coefficients of the different majors to determine which majors had the largest positive coefficients as that indicated which majors had the highest salaries on average.

#### Sect 4

We fit a linear model \`Salary \~ GPA + Sex \* MajorCategory\` (adjusting for GPA) and examined \`summary(sal_lm_sex_major)\` to assess main effects and the Sex × MajorCategory interaction. We generated a balanced prediction grid over all \`MajorCategory\` levels crossed with \`Sex ∈ {F, M}\` at a fixed GPA of 3.5, ensuring factor levels in \`newdata\` matched the model’s training levels, and obtained fitted values via \`predict()\`. We reshaped predictions to wide format to compute the within major gender gap Delta (difference) = (Salary of Males - Salary of Female) at GPA 3.5 for each major. Finally, we visualized these gaps with a horizontal bar chart (ggplot2), ordering majors by Delta and coloring bars by direction (“Male \> Female” vs. “Female \> Male”) to highlight both magnitude and sign of predicted differences.

#### Sect 5

We compared models with and without interactions. The F-test showed the model with interactions was significant. But their adjusted R-squared values are similar, and the K-fold CV results show that the predictive RMSE is similar. So we consider the simpler model to be a better choice. We also compared our predictive rmse to the sd of the dataset and saw that our rmse was significantly smaller than the sd, which means it better explained the variance in the data.

## Code Appendix

## 
