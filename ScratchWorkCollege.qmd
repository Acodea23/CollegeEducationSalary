---
title: "College Scratch"
author: "Corbin B; Matthew W"
format: pdf
editor: visual
---

```{r}

#library for data cleaning and graphs

library(tidyverse)

```

```{r}

# reading in data and creating factors
sal_df <- vroom::vroom("Salary.csv")

sal_df <- sal_df |>
  mutate(
    MajorCategory = factor(MajorCategory),
    Sex = factor(Sex)
  )

# creating a linear model. Salary predicted my Major, GPA and sex. No interaction
sal_lm<-lm(Salary~ .,sal_df)
#linear model that includes an interaction between GPA and MajorCategory
sal_lm_int_GPA_MAJ  <- lm(Salary ~ GPA * MajorCategory + Sex, data = sal_df)

head(sal_df)
```

## Impact of GPA - Corbin

### What impact, if any, does GPA have on salary? Do you think students should be hyper-anxious about grades?

```{r}


# 1) Pull GPA beta (estimate) and p-value from the summary object
smry <- summary(sal_lm)
coef_mat <- smry$coefficients

gpa_estimate <- coef_mat["GPA", "Estimate"]
gpa_pvalue   <- coef_mat["GPA", "Pr(>|t|)"]

# 2) Confidence interval (default 95%)
gpa_ci <- confint(sal_lm, "GPA", level = 0.95)

# Print nicely
cat("GPA beta (Estimate):", round(gpa_estimate, 4), "\n")
cat("GPA p-value        :", signif(gpa_pvalue, 4), "\n")
cat("GPA 95% CI         : [",
    round(gpa_ci[1], 4), ", ", round(gpa_ci[2], 4), "]\n", sep = "")


```

### Is the effect of GPA different for different majors (does GPA matter more for some majors than others)?.

```{r}

# -------------------------
# Helper: per-major GPA effects (beta, p, 95% CI), no SE/stat printed
# -------------------------
per_major_gpa_effects <- function(model, major_var = "MajorCategory", gpa_var = "GPA", level = 0.95) {
  sm   <- summary(model)
  cf   <- sm$coefficients
  V    <- vcov(model)
  levs <- levels(model$model[[major_var]])
  ref  <- levs[1]  # reference level

  term_gpa <- gpa_var
  out <- list()

  # Baseline (reference major)
  est_ref <- cf[term_gpa, "Estimate"]
  se_ref  <- cf[term_gpa, "Std. Error"]
  p_ref   <- cf[term_gpa, "Pr(>|t|)"]

  alpha <- 1 - level
  tcrit <- qt(1 - alpha/2, df = sm$df[2])
  ci_ref <- c(est_ref - tcrit * se_ref, est_ref + tcrit * se_ref)

  out[[ref]] <- tibble(
    MajorCategory = ref,
    estimate      = est_ref,
    p_value       = p_ref,
    conf_low      = ci_ref[1],
    conf_high     = ci_ref[2]
  )

  # Non-reference majors: slope = beta_GPA + beta_interaction
  for (k in levs[-1]) {
    ti1 <- paste0(gpa_var, ":", major_var, k)
    ti2 <- paste0(major_var, k, ":", gpa_var)
    ti  <- c(ti1, ti2)[c(ti1, ti2) %in% rownames(cf)][1]
    if (is.na(ti)) next

    est <- cf[term_gpa, "Estimate"] + cf[ti, "Estimate"]
    var_ <- V[term_gpa, term_gpa] + V[ti, ti] + 2 * V[term_gpa, ti]
    se   <- sqrt(var_)
    tval <- est / se
    pval <- 2 * pt(abs(tval), df = sm$df[2], lower.tail = FALSE)
    ci   <- c(est - tcrit * se, est + tcrit * se)

    out[[k]] <- tibble(
      MajorCategory = k,
      estimate      = est,
      p_value       = pval,
      conf_low      = ci[1],
      conf_high     = ci[2]
    )
  }

  bind_rows(out) |>
    arrange(MajorCategory)
}



cat("\n=== Interaction terms: difference in GPA slope vs. reference major ===\n")
interaction_tbl |>
  mutate(
    across(c(estimate, conf_low, conf_high), ~round(.x, 3)),
    p_value = signif(p_value, 3)
  ) |>
  print(n = Inf)

# -------------------------
# 3) F-tests (does interaction improve fit?)
# -------------------------
cat("\n=== Nested model comparison (no interaction vs. with interaction) ===\n")
print(anova(sal_lm, sal_lm_int_GPA_MAJ))

cat("\n=== Drop1 test (joint test of GPA:MajorCategory block) ===\n")
print(drop1(sal_lm_int_GPA_MAJ, test = "F"))





#MAKE PREDICTION FOR THIS


```

## Salaries Across Majors - Matthew

```{r}

# code to perform f-test between base lm, and an lm that doesn't include Major
print(anova(sal_lm, lm(Salary~ -MajorCategory,sal_df)))

# we see that major is significant, so now we view the summary of the model with major.
summary(sal_lm)

maj_df <- expand.grid(Sex = "F", GPA = 3.5, MajorCategory = unique(sal_df$MajorCategory))

maj_preds <- predict(sal_lm, new_data = as.data.frame(maj_df))

```

Yes, we see that "Engineering", "Computers and Mathematics", and "Physical Sciences" make the most.

```{r}

# make df for diff majors holding constant of female w/ 3.5 GPA
maj_df <- expand.grid(Sex = "F", GPA = 3.5, MajorCategory = unique(sal_df$MajorCategory))

# predict salaries for diff majors
maj_preds <- predict(sal_lm, newdata = maj_df)

ggplot(data = maj_preds)+
  geom_bar()


```

```{r}

# Ensure you used the correct arg for base R lm
maj_preds <- predict(sal_lm, newdata = maj_df, se.fit = TRUE)

# Bind predictions back to maj_df
plot_df <- maj_df %>%
  mutate(
    .pred = maj_preds$fit,
  ) %>%
  # Order majors by predicted value for a nicer chart
  mutate(MajorCategory = reorder(MajorCategory, .pred))

library(scales)

ggplot(plot_df, aes(x = MajorCategory, y = .pred)) +
  geom_col(fill = "#4472C4") +
  coord_flip() +  # if you prefer horizontal bars (often easier to read)
  scale_y_continuous(
    breaks = scales::breaks_pretty(n = 5),      # more ticks
    minor_breaks = waiver(),                     # add minor gridlines
    labels = label_number(big.mark = ",")        # or label_dollar() if these are $ values
    # e.g., labels = label_dollar(accuracy = 1)
  ) +
  theme_minimal(base_size = 12) +
  theme(
    panel.grid.minor.y = element_line(color = "grey85"),  # emphasize minor gridlines
    panel.grid.major.y = element_line(color = "grey80")
  ) +
  labs(x = "Major category", y = "Predicted Salary", title = "Predicted Salary by Major")
```

## Salaries for Women and Men - Corbin

```{r}
sal_lm_sex_major <- lm(
  Salary ~ GPA + Sex * MajorCategory,
  data = sal_df
)

summary(sal_lm_sex_major)

```

## Other Factors - Matthew

```{r}

# linear model using all predictors and no interactions. As seen above, just defined again for clarity
sal_lm<-lm(Salary~ .,sal_df)

# linear model using all predictors and interactions found to be significant:
sal_interaction_lm <- lm(Salary ~ MajorCategory * Sex + MajorCategory * GPA, data = sal_df)



# par(mfrow = c(2,2))
# plot(sal_interaction_lm)

# function to perform k-fold cv for a single fold.
# take input of k, the kth fold
# calculates rmse for the models with and without interactions
# returns difference of rmse of the 2

cross_validate <- function(k){
  val_set <- sal_df |> filter(folds == k)
  train_set <- sal_df |> filter(folds != k)
  
  preds_1 <- predict.lm(lm(Salary ~ MajorCategory * Sex + MajorCategory * GPA, data = train_set),
            newdata = val_set)
  rmse_1 <- sqrt(mean((preds_1 - val_set[["Salary"]])^2))
  
  preds_2 <- predict.lm(lm(Salary ~ MajorCategory + Sex + GPA, data = train_set),
            newdata = val_set)
  rmse_2 <- sqrt(mean((preds_2 - val_set[["Salary"]])^2))
  
  rmse_1 - rmse_2
}

K <- 20

# randomly creates partitions for folds
folds <- rep(1:K, length = nrow(sal_df))|>
  sample()


rmse_results <- sapply(1:K, FUN = cross_validate)

# results of k-fold validation comparison
print(summary(rmse_results))
hist(rmse_results)



```

```{r}

# function similar to above
#instead of finding difference, just calclates rmse for 1 and returns it
cross_validate_one <- function(k){
  val_set <- sal_df |> filter(folds == k)
  train_set <- sal_df |> filter(folds != k)
  
  preds <- predict.lm(lm(Salary ~ Sex + MajorCategory + GPA, data = train_set),
            newdata = val_set)
  sqrt(mean((preds - val_set[["Salary"]])^2))
}

K <- 20

# see above cell
folds <- rep(1:K, length = nrow(sal_df))|>
  sample()


rmse_results <- sapply(1:K, FUN = cross_validate_one)

# statistics from k_folds
print(sd(sal_df[["Salary"]]))
print(mean(rmse_results))
print(summary(rmse_results))
```

## Model Validation

```{r}

# creates a plot of various lm assumptions
par(mfrow = c(2,2))
plot(sal_lm)

```
